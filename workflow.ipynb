{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import yfinance as yf\n",
    "from yahoofinancials import YahooFinancials\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "DATADIR = 'stock_files'\n",
    "GRAPHDIR = 'stock_graphs'\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math RMSE Function\n",
    "def return_rmse(test,predicted):\n",
    "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
    "    print(\"The root mean squared error is {}.\".format(rmse))\n",
    "\n",
    "def enrich_stock_with_smas(stock_pd):\n",
    "    stock_pd[\"SMA2\"] = stock_pd['Close'].rolling(window=2).mean()\n",
    "    stock_pd[\"SMA5\"] = stock_pd['Close'].rolling(window=5).mean()\n",
    "    stock_pd[\"SMA10\"] = stock_pd['Close'].rolling(window=10).mean()\n",
    "    stock_pd[\"SMA25\"] = stock_pd['Close'].rolling(window=25).mean()\n",
    "    stock_pd[\"SMA50\"] = stock_pd['Close'].rolling(window=50).mean()\n",
    "    stock_pd[\"SMA90\"] = stock_pd['Close'].rolling(window=90).mean()\n",
    "    stock_pd[\"SMA120\"] = stock_pd['Close'].rolling(window=120).mean()\n",
    "    stock_pd[\"SMA180\"] = stock_pd['Close'].rolling(window=180).mean()\n",
    "    e_stock_pd = stock_pd\n",
    "    return e_stock_pd\n",
    "\n",
    "def enrich_stock_with_bbs(stock_pd):\n",
    "    #Bollinger Bands\n",
    "    stock_pd['EWMA'] = stock_pd['Close'].ewm(halflife=0.5, min_periods=20).mean()\n",
    "    stock_pd['middle_band'] = stock_pd['Close'].rolling(window=20).mean()\n",
    "    stock_pd['upper_band'] = stock_pd['Close'].rolling(window=20).mean() + stock_pd['Close'].rolling(window=20).std()*2\n",
    "    stock_pd['lower_band'] = stock_pd['Close'].rolling(window=20).mean() - stock_pd['Close'].rolling(window=20).std()*2\n",
    "    e_stock_pd = stock_pd\n",
    "    return e_stock_pd\n",
    "\n",
    "def print_sma_chart_days(stock_ticker, stock_pd, nDays):\n",
    "    dt_latest = stock_pd.iloc[-1:].index[0]\n",
    "    if isinstance(dt_latest, str):\n",
    "        dt_latest = datetime.strptime(dt_latest,\"%Y-%m-%d\")\n",
    "    dt_previous = dt_latest - timedelta(days=nDays)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.plot(stock_pd['SMA2'], 'r--', label=\"SMA2\")\n",
    "    plt.plot(stock_pd['SMA5'], 'y--', label=\"SMA5\")\n",
    "    plt.plot(stock_pd['SMA10'], 'g--', label=\"SMA10\")\n",
    "    plt.plot(stock_pd['SMA50'], 'c--', label=\"SMA50\")\n",
    "    plt.plot(stock_pd['SMA90'], 'm--', label=\"SMA90\")\n",
    "    plt.plot(stock_pd['SMA180'], 'b--', label=\"SMA180\")\n",
    "    plt.plot(stock_pd['Close'], label=\"Close\")\n",
    "    plt.title(\"[\"+stock_ticker+\"] \"+\"Stock Price with SMAs from [\"+dt_previous.strftime(\"%Y-%m-%d\")+\" to \"+dt_latest.strftime(\"%Y-%m-%d\")+\"] | [\"+str(nDays)+\"] Days\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price [$]\")\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlim([dt_previous, dt_latest])\n",
    "    plt.legend()\n",
    "    \n",
    "    stock_graph_name = stock_ticker+\"_\"+str(nDays)+\"_\"+dt_previous.strftime(\"%Y-%m-%d\")+\"_\"+dt_latest.strftime(\"%Y-%m-%d\")\n",
    "    dt_str_latest_date = dt_latest.strftime(\"%Y-%m-%d\")\n",
    "    path_ts = os.path.join(GRAPHDIR,dt_str_latest_date)\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(path_ts):\n",
    "            os.makedirs(path_ts)\n",
    "        plt.savefig(path_ts+r'/'+stock_graph_name+r'.png')\n",
    "        print(\"Saved Plot as: [\"+path_ts+r'/'+stock_graph_name+\".png]\")\n",
    "    except:\n",
    "        print(\"Error! Could not save Plot as: [\"+path_ts+r'/'+stock_graph_name+\".png]\")\n",
    "    plt.show()\n",
    "\n",
    "def last_stock_date(stock_pd):\n",
    "    return stock_pd.iloc[-1:].index[0].strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "def first_stock_date(stock_pd):\n",
    "    return stock_pd.iloc[0:].index[0].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def save_dataframe_as_csv(stock_pd,stock_ticker):\n",
    "    dt_str_first_date = stock_pd.iloc[0:].index[0].strftime(\"%Y-%m-%d\")\n",
    "    dt_str_latest_date = stock_pd.iloc[-1:].index[0].strftime(\"%Y-%m-%d\")\n",
    "    stock_file_name = stock_ticker+\"_\"+dt_str_first_date+\"_\"+dt_str_latest_date+\".csv\"\n",
    "    try:\n",
    "        path_ts = os.path.join(DATADIR,dt_str_latest_date)\n",
    "        if not os.path.exists(path_ts):\n",
    "            os.makedirs(path_ts)\n",
    "        stock_pd.to_csv(path_ts+r'/'+stock_file_name)\n",
    "        print(\"Saved DataFrame as: [\"+path_ts+r'/'+stock_file_name+\"]\")\n",
    "    except:\n",
    "        print(\"Error! Could not save Dataframe as: [\"+path_ts+r'/'+stock_file_name+\"]\")\n",
    "\n",
    "def convert_df_to_pd(stock_df):\n",
    "    stock_pd = pd.DataFrame(stock_df)\n",
    "    return stock_pd\n",
    "\n",
    "def online_process_stock_once(stock_ticker,nDays):\n",
    "    stock_df = yf.download(stock_ticker)\n",
    "    stock_pd = convert_df_to_pd(stock_df)\n",
    "    stock_pd = enrich_stock_with_smas(stock_pd)\n",
    "    stock_pd = enrich_stock_with_bbs(stock_pd)\n",
    "    save_dataframe_as_csv(stock_pd,stock_ticker)\n",
    "    #print(stock_ticker)\n",
    "    print_sma_chart_days(stock_ticker,stock_pd,nDays)\n",
    "\n",
    "def get_list_of_files_in_dir(dir_name):\n",
    "    list_of_files_only = [f for f in listdir(dir_name) if isfile(join(dir_name, f))]\n",
    "    return list_of_files_only\n",
    "\n",
    "def read_offline_csv_to_dataframe(dir_name,file_name):\n",
    "    read_stock_pd = pd.read_csv(DATADIR+r'/'+file_name)\n",
    "    read_stock_pd['Date'] = pd.to_datetime(read_stock_pd['Date'])\n",
    "    read_stock_pd.set_index('Date', inplace=True)\n",
    "    return read_stock_pd\n",
    "\n",
    "def get_stock_ticker_name_from_file_name(file_name):\n",
    "    m = re.search('(^[a-zA-Z]+?)_', file_name)\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "    return found\n",
    "\n",
    "def get_stock_dataframe_from_local(dir_name,stock_ticker):\n",
    "    stock_pd = pd.DataFrame()\n",
    "    list_of_files = get_list_of_files_in_dir(dir_name)\n",
    "    for file_name in list_of_files:\n",
    "        current_stock_title = get_stock_ticker_name_from_file_name(file_name)\n",
    "        if stock_ticker == current_stock_title:\n",
    "            stock_pd = read_offline_csv_to_dataframe(dir_name,file_name)\n",
    "            break\n",
    "    return stock_pd\n",
    "\n",
    "def offline_process_stock_once(dir_name,stock_ticker,nDays):\n",
    "    stock_pd = get_stock_dataframe_from_local(dir_name,stock_ticker)\n",
    "    print(stock_ticker)\n",
    "    print_sma_chart_days(stock_ticker,stock_pd,nDays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN ONLINE UNIT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_to_iterate = ['TSLA']\n",
    "for ticker_name in tickers_to_iterate:\n",
    "    online_process_stock_once(ticker_name,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ML KERAS EXPERIMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRODUCTION ONLINE EXPERIMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_to_iterate = ['TSLA', 'GOOG', 'AMZN', 'AAPL', 'MSFT', 'FB', 'UBER', 'SNAP', 'NVDA', 'AMD', 'GOOGL', 'WORK', 'SHOP', 'CRM', 'ADBE', 'DBX', 'INTC', 'QCOM', 'MU']\n",
    "for ticker_name in tickers_to_iterate:\n",
    "    online_process_stock_once(ticker_name,180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRODUCTION OFFLINE EXPERIMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_to_iterate = ['TSLA', 'GOOG', 'AMZN', 'AAPL', 'MSFT', 'FB', 'UBER', 'SNAP', 'NVDA', 'AMD', 'GOOGL', 'WORK', 'SHOP', 'CRM', 'ADBE', 'DBX', 'INTC', 'QCOM', 'MU']\n",
    "for ticker_name in tickers_to_iterate:\n",
    "    offline_process_stock_once(DATADIR,ticker_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
